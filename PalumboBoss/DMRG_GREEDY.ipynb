{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de046831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Union, Tuple\n",
    "from tenpy.networks.site import SpinSite\n",
    "from tenpy.linalg import np_conserved as npc\n",
    "from tenpy.linalg.np_conserved import Array\n",
    "from tenpy.networks.mpo import MPO\n",
    "from tenpy.models.model import MPOModel\n",
    "from tenpy.models.lattice import Chain\n",
    "from tenpy.networks.mps import MPS  \n",
    "from tenpy.algorithms.network_contractor import ncon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "978c73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_L(d: int, Dl: int, Dr: int, seed=None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Tensore L_k di shape (d, Dl, Dr).\n",
    "    Su ogni riga non nulla c’è un solo '1' in colonna casuale.\n",
    "    Ogni riga (x, i) ha probabilità 1/(Dr+1) di essere tutta zero.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    L = np.zeros((d, Dl, Dr), dtype=np.uint8)\n",
    "\n",
    "    # J[x, i] ∈ {0, ..., Dr} con distribuzione uniforme\n",
    "    J = rng.integers(0, Dr + 1, size=(d, Dl))\n",
    "    mask = (J != Dr)  # True dove mettiamo un '1'\n",
    "\n",
    "    xs, is_ = np.where(mask)\n",
    "    js = J[xs, is_]\n",
    "    L[xs, is_, js] = 1\n",
    "\n",
    "    return L\n",
    "\n",
    "\n",
    "def random_R(d: int, Dl: int, Dr: int, seed=None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Tensore R_k di shape (d, Dl, Dr).\n",
    "    Su ogni colonna non nulla c’è un solo '1' in riga casuale.\n",
    "    Ogni colonna (x, j) ha probabilità 1/(Dl+1) di essere tutta zero.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    R = np.zeros((d, Dl, Dr), dtype=np.uint8)\n",
    "\n",
    "    # I[x, j] ∈ {0, ..., Dl} con distribuzione uniforme\n",
    "    I = rng.integers(0, Dl + 1, size=(d, Dr))\n",
    "    mask = (I != Dl)\n",
    "\n",
    "    xs, js = np.where(mask)\n",
    "    is_ = I[xs, js]\n",
    "    R[xs, is_, js] = 1\n",
    "\n",
    "    return R\n",
    "\n",
    "\n",
    "def random_A1(d: int, D: int, seed=None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Primo sito: shape (d, 1, D). Binario libero.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Estraggo in {0, 1}, uniforme, direttamente in uint8\n",
    "    return rng.integers(0, 2, size=(d, 1, D), dtype=np.uint8)\n",
    "\n",
    "def wrap_site_tensor(T: np.ndarray):\n",
    "    \"\"\"(d, Dl, Dr) -> npc.Array labels ['vL','p','vR'] shape (Dl, d, Dr).\"\"\"\n",
    "    # transpose is a view; np Array creation happens inside TeNPy\n",
    "    return npc.Array.from_ndarray_trivial(T.transpose(1, 0, 2), labels=['vL', 'p', 'vR'])\n",
    "\n",
    "def tenpy_sites_and_svs(d: int, right_dims):\n",
    "    \"\"\"\n",
    "    Costruisce i siti TenPy e i singolar values iniziali\n",
    "    per una MPS con dimensione fisica d e bond-dims right_dims.\n",
    "    right_dims ha lunghezza N, con N = numero siti.\n",
    "    \"\"\"\n",
    "    N = len(right_dims)\n",
    "    S = (d - 1) / 2.0\n",
    "    site = SpinSite(S=S, conserve=None)\n",
    "    lattice = Chain(L=N, site=site)\n",
    "    sites = lattice.mps_sites()\n",
    "\n",
    "    # svs: D_0, D_1, ..., D_{N-1}, D_N con D_0 = D_N = 1\n",
    "    svs = [np.ones(1, dtype=float)]\n",
    "    svs.extend(np.ones(D, dtype=float) for D in right_dims[:-1])\n",
    "    svs.append(np.ones(1, dtype=float))\n",
    "\n",
    "    return sites, svs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecb06ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def site_tensor_from_Bi(Bi: dict, d: int, *, strict_keys: bool = True):\n",
    "    \"\"\"\n",
    "    Costruisce T[x] = Bi[x] con fallback a zeri. T shape: (d, Dl, Dr).\n",
    "\n",
    "    - Valida che tutte le matrici abbiano la stessa shape 2D.\n",
    "    - Se strict_keys=True, richiede chiavi intere in [0, d-1].\n",
    "    - Usa una 'fast path' quando Bi contiene tutte le chiavi 0..d-1 (stack).\n",
    "    \"\"\"\n",
    "    if not Bi:\n",
    "        raise ValueError(\"Bi non può essere vuoto: serve almeno una matrice per fissare (Dl, Dr).\")\n",
    "\n",
    "    # --- keys validation (vectorized) ---\n",
    "    keys = np.fromiter(Bi.keys(), dtype=int, count=len(Bi))\n",
    "    if strict_keys:\n",
    "        bad_keys = [k for k in Bi.keys() if not (0 <= k < d)]\n",
    "        if bad_keys:\n",
    "            raise ValueError(f\"Chiavi fuori range [0, {d-1}]: {bad_keys}\")\n",
    "\n",
    "    # tutte le matrici devono avere la stessa shape 2D\n",
    "    shapes = {np.shape(M) for M in Bi.values()}\n",
    "    if len(shapes) != 1:\n",
    "        raise ValueError(f\"shape incoerenti in Bi: {shapes}\")\n",
    "    Dl, Dr = next(iter(shapes))\n",
    "    if len((Dl, Dr)) != 2:\n",
    "        raise ValueError(f\"Le matrici in Bi devono essere 2D, shape trovata: {Dl, Dr}\")\n",
    "\n",
    "    # dtype comune (considera anche i fallback a 0)\n",
    "    dtype = np.result_type(*[np.asarray(Bi.get(x, 0)).dtype for x in range(d)])\n",
    "\n",
    "    T = np.zeros((d, Dl, Dr), dtype=dtype)\n",
    "    zero_block = np.zeros((Dl, Dr), dtype=dtype)\n",
    "\n",
    "    for x in range(d):\n",
    "        Mx = np.asarray(Bi.get(x, zero_block), dtype=dtype)\n",
    "        if Mx.shape != (Dl, Dr):\n",
    "            raise ValueError(f\"Bi[{x}] ha shape {Mx.shape}, atteso {(Dl, Dr)}\")\n",
    "        T[x] = Mx\n",
    "\n",
    "    return T, Dl, Dr\n",
    "\n",
    "\n",
    "def build_mps(B_list, d: int):\n",
    "    \"\"\"\n",
    "    Costruisce un MPS TeNPy dai blocchi per-sito (dizionari Bi).\n",
    "    - Verifica vincoli di bordo (Dl[0]==1, Dr[N-1]==1) e coerenza dei bond interni.\n",
    "    - Converte ciascun sito in npc.Array con labels ['vL','p','vR'].\n",
    "    - Inizializza vettori di Schmidt = 1.\n",
    "    \"\"\"\n",
    "    # validate d una sola volta (cheap branch)\n",
    "    if not isinstance(d, (int, np.integer)) or d < 1:\n",
    "        raise ValueError(\"`d` deve essere intero positivo.\")\n",
    "\n",
    "    N = len(B_list)\n",
    "    if N == 0:\n",
    "        raise ValueError(\"B_list non può essere vuoto.\")\n",
    "\n",
    "    A = []\n",
    "    right_dims = []\n",
    "    prev_Dr = None\n",
    "\n",
    "    for i, Bi in enumerate(B_list):\n",
    "        T, Dl, Dr = site_tensor_from_Bi(Bi, d, strict_keys=True)\n",
    "\n",
    "        # Bordo sinistro\n",
    "        if i == 0:\n",
    "            if Dl != 1:\n",
    "                raise ValueError(f\"sito {i}: Dl deve essere 1 (bordo sinistro), trovato {Dl}\")\n",
    "        else:\n",
    "            # Bond interno: Dl(i) deve coincidere con Dr(i-1)\n",
    "            if Dl != prev_Dr:\n",
    "                raise ValueError(\n",
    "                    f\"mismatch bond interno tra sito {i-1} e {i}: Dr[{i-1}]={prev_Dr}, Dl[{i}]={Dl}\"\n",
    "                )\n",
    "\n",
    "        # Bordo destro\n",
    "        if i == N - 1 and Dr != 1:\n",
    "            raise ValueError(f\"sito {i}: Dr deve essere 1 (bordo destro), trovato {Dr}\")\n",
    "\n",
    "        # Wrap immediato (evita una lista intermedia di tensori)\n",
    "        A.append(wrap_site_tensor(T))\n",
    "        right_dims.append(Dr)\n",
    "        prev_Dr = Dr\n",
    "\n",
    "    sites, svs = tenpy_sites_and_svs(d, right_dims)\n",
    "    return MPS(sites, A, svs, bc='finite', form='A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a80df12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_B_list(S0, K, N, d_op, m_op, u_op, pd, pu):\n",
    "    pmid = 1 - pd - pu\n",
    "    if not (0 <= pd <= 1 and 0 <= pu <= 1 and pd + pu <= 1):\n",
    "        raise ValueError(\"Probabilità non valide: servono pd, pu >=0 e pd+pu <= 1\")\n",
    "\n",
    "    B_list = []\n",
    "\n",
    "    # Sito 1: (1,2)\n",
    "    B1 = {\n",
    "        0: row12[0][None, :].astype(dtype, copy=False),\n",
    "        1: row12[1][None, :].astype(dtype, copy=False),\n",
    "        2: row12[2][None, :].astype(dtype, copy=False),\n",
    "    }\n",
    "\n",
    "    # ---------- Middle sites i=2..N-1: shape (2,2) ----------\n",
    "    # [[ op*p , (S_over*op - K)*p ],\n",
    "    #  [   p  ,          1        ]]\n",
    "    one = np.array(1.0, dtype=dtype)\n",
    "    Bi_template = {\n",
    "        0: np.array([[TL[0], TR[0]],\n",
    "                     [BL[0], one  ]], dtype=dtype),\n",
    "        1: np.array([[TL[1], TR[1]],\n",
    "                     [BL[1], one  ]], dtype=dtype),\n",
    "        2: np.array([[TL[2], TR[2]],\n",
    "                     [BL[2], one  ]], dtype=dtype),\n",
    "    }\n",
    "\n",
    "    # ---------- Last site N: shape (2,1) ----------\n",
    "    # [[ op*p ],\n",
    "    #  [  p   ]]\n",
    "    BN = {\n",
    "        0: np.array([[TL[0]],\n",
    "                     [BL[0]]], dtype=dtype),\n",
    "        1: np.array([[TL[1]],\n",
    "                     [BL[1]]], dtype=dtype),\n",
    "        2: np.array([[TL[2]],\n",
    "                     [BL[2]]], dtype=dtype),\n",
    "    }\n",
    "\n",
    "    # ---------- Assemble B_list ----------\n",
    "    B_list = [B1]\n",
    "    if N > 2:\n",
    "        if share_middle:\n",
    "            # fastest: reuse the exact same dict object for all middle sites\n",
    "            B_list.extend([Bi_template] * (N - 2))\n",
    "        else:\n",
    "            # safer: separate dicts pointing to the same arrays (still shared)\n",
    "            B_list.extend([Bi_template.copy() for _ in range(N - 2)])\n",
    "            # If you truly need fully independent arrays per site, use:\n",
    "            # for _ in range(N - 2):\n",
    "            #     B_list.append({k: v.copy() for k, v in Bi_template.items()})\n",
    "    B_list.append(BN)\n",
    "    return B_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56e77081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mps_AR(d: int, N: int, D: int, seed=None):\n",
    "    \"\"\"\n",
    "    Crea b(x) con bond dimensione D:\n",
    "      A1: (d, 1, D)   [NB: original line below uses D=d; see NOTE]\n",
    "      R2..R_{N-1}: (d, D, D)\n",
    "      RN: (d, D, 1)\n",
    "    \"\"\"\n",
    "    # controlli basilari\n",
    "    if N < 2:\n",
    "        raise ValueError(\"N deve essere >= 2 per avere A1 e almeno un R.\")\n",
    "    if d < 1 or int(d) != d:\n",
    "        raise ValueError(\"`d` deve essere intero positivo.\")\n",
    "    if D < 1 or int(D) != D:\n",
    "        raise ValueError(\"`D` deve essere intero positivo.\")\n",
    "    d = int(d)\n",
    "    D = int(D)\n",
    "\n",
    "    A1 = random_A1(d, d, seed=seed)\n",
    "\n",
    "    Rs = []\n",
    "    for k in range(2, N):\n",
    "        sk = None if seed is None else seed + k\n",
    "        Rs.append(random_R(d, Dl=D, Dr=D, seed=sk))\n",
    "\n",
    "    sN = None if seed is None else seed + N\n",
    "    RN = random_R(d, Dl=D, Dr=1, seed=sN)\n",
    "\n",
    "    tensors = [A1, *Rs, RN]\n",
    "\n",
    "    # wrap TenPy (cheap comprehensions; no semantic changes)\n",
    "    A = [wrap_site_tensor(T) for T in tensors]\n",
    "    right_dims = [T.shape[2] for T in tensors]\n",
    "    sites, svs = tenpy_sites_and_svs(d, right_dims)\n",
    "    return MPS(sites, A, svs, bc='finite', form='A')\n",
    "\n",
    "\n",
    "def build_mps_AR_bond(d: int, N: int, D: int, seed=None):\n",
    "    \"\"\"\n",
    "    Crea un MPS psi con N siti (N dispari) e bond che crescono verso il centro\n",
    "    come Dl -> min(Dl * d, D) e poi decrescono simmetricamente.\n",
    "\n",
    "    Tensore sito i (0-based) ha shape (d, Dl_i, Dr_i).\n",
    "    \"\"\"\n",
    "    # controlli basilari\n",
    "    if N < 3 or N % 2 == 0:\n",
    "        raise ValueError(\"N deve essere dispari e >= 3.\")\n",
    "    if d < 1 or int(d) != d:\n",
    "        raise ValueError(\"`d` deve essere intero positivo.\")\n",
    "    if D < 1 or int(D) != D:\n",
    "        raise ValueError(\"`D` deve essere intero positivo.\")\n",
    "    d = int(d)\n",
    "    D = int(D)\n",
    "\n",
    "    # half = indice del bond centrale\n",
    "    half = N // 2  # per N=7 -> 3\n",
    "\n",
    "    # costruiamo i bond da sinistra fino al centro\n",
    "    bonds = [1]   # bond[0] = 1\n",
    "    Dl = 1\n",
    "    for k in range(1, half + 1):\n",
    "        candidate = Dl * d\n",
    "        Dr = candidate if candidate < D else D\n",
    "        bonds.append(Dr)\n",
    "        Dl = Dr\n",
    "\n",
    "    # riflettiamo per avere simmetria: [1, ..., centro, ..., 1]\n",
    "    # es: [1,3,9,10] -> [1,3,9,10,10,9,3,1]\n",
    "    bonds = bonds + bonds[::-1]\n",
    "    assert len(bonds) == N + 1  # N siti -> N+1 bond\n",
    "\n",
    "    tensors = []\n",
    "\n",
    "    # primo sito: Dl = bonds[0]=1, Dr = bonds[1]\n",
    "    Dr0 = bonds[1]\n",
    "    # Keep exact current behavior of your A1 generator:\n",
    "    # your build_mps_AR_bond already calls random_A1(d, Dr0, seed=seed)\n",
    "    tensors[0] = random_A1(d, Dr0, seed=sA)\n",
    "\n",
    "    # sites 1..N-1\n",
    "    # comprehension with enumerate keeps Python overhead low\n",
    "    tensors[1:] = [\n",
    "        random_R(d, Dl=bonds[i], Dr=bonds[i+1], seed=s_list[i-1])\n",
    "        for i in range(1, N)\n",
    "    ]\n",
    "\n",
    "    # wrap TenPy\n",
    "    A = [wrap_site_tensor(T) for T in tensors]\n",
    "    right_dims = [T.shape[2] for T in tensors]\n",
    "    sites, svs = tenpy_sites_and_svs(d, right_dims)\n",
    "    return MPS(sites, A, svs, bc='finite', form='A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecc1a9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_x psi(x)b(x) = -11.83708977017639\n"
     ]
    }
   ],
   "source": [
    "S0, K, N = 1.0, 0.2, 21\n",
    "d_op, m_op, u_op = 0.9, 1.0, 3\n",
    "pd, pu = 0.2, 0.4   \n",
    "\n",
    "B_list = build_B_list(S0, K, N, d_op, m_op, u_op, pd, pu)\n",
    "\n",
    "b = build_mps(B_list, d=3)\n",
    "\n",
    "psi = build_mps_AR_bond(d=3, N=len(B_list), D=9)\n",
    "\n",
    "val = b.overlap(psi)\n",
    "print(\"sum_x psi(x)b(x) =\", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e2b6f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract_left(tensor, i, N):\n",
    "    A = [tensor.get_B(k) for k in range(i-1)]   # each: (Dl, d, Dr)\n",
    "    #print(len(A))\n",
    "\n",
    "    if i == 1:\n",
    "        return None   # oppure semplicemente \"return\" per terminare senza valore\n",
    "\n",
    "    if i > N:\n",
    "        raise ValueError(f\"Indice i={i} maggiore del numero di siti N={N}.\")\n",
    "    \n",
    "    if i <= 0:\n",
    "        raise ValueError(f\"Indice i={i} minore o uguale a 0.\")\n",
    "\n",
    "\n",
    "    # ncon index bookkeeping:\n",
    "    # open legs use negative integers; positive integers are contracted\n",
    "    # A0: (-1, -2,  1)\n",
    "    # A1: ( 1, -3,  2)\n",
    "    # A2: ( 2, -4,  3)\n",
    "    # ...\n",
    "    # A_{i-2}: (i-2, -(i), -(i+1))  # the final right bond stays open\n",
    "\n",
    "    con_tensors = []\n",
    "    con_indices = []\n",
    "    if len(A) == 1:\n",
    "        con_indices.append([-1, -2, -3])\n",
    "        con_tensors.append(A[0])\n",
    "    else:\n",
    "        for k, Ak in enumerate(A):\n",
    "            if k == 0:                                  # first site\n",
    "                con_tensors.append(Ak)\n",
    "                con_indices.append([-1, -2, 1])\n",
    "            elif k < len(A) - 1:                        # middle sites\n",
    "                con_tensors.append(Ak)\n",
    "                con_indices.append([k, -(k+2), k+1])\n",
    "            else:                                       # last of the block\n",
    "                con_tensors.append(Ak)\n",
    "                con_indices.append([k, -(k+2), -(k+3)])\n",
    "    #print(con_indices)\n",
    "\n",
    "    # result has open legs: [-1 (left=1), -2..-(i) (physicals), -(i+1) (right bond Di-1)]\n",
    "    T = ncon(con_tensors, con_indices)\n",
    "    # T.shape == (1, d, d, ..., d, D_{i-1})   # (i-1) copies of d\n",
    "\n",
    "    return T\n",
    "\n",
    "def contract_right(tensor, i, N):\n",
    "    A = [tensor.get_B(k) for k in range(i,N)]   # each: (Dl, d, Dr)\n",
    "    #print(len(A))\n",
    "\n",
    "    if i == N:\n",
    "        return None   # oppure semplicemente \"return\" per terminare senza valore\n",
    "\n",
    "    if i > N:\n",
    "        raise ValueError(f\"Indice i={i} maggiore del numero di siti N={N}.\")\n",
    "    \n",
    "    if i <= 0:\n",
    "        raise ValueError(f\"Indice i={i} minore o uguale a 0.\")\n",
    "\n",
    "    # ncon index bookkeeping:\n",
    "    # open legs use negative integers; positive integers are contracted\n",
    "    # Ai: (-1, -2,  1)\n",
    "    # Ai+1: ( 1, -3,  2)\n",
    "    # Ai+2: ( 2, -4,  3)\n",
    "    # ...\n",
    "    # AN-1: (i-2, -(i), -(i+1))  # the final right bond stays open\n",
    "\n",
    "    con_tensors = []\n",
    "    con_indices = []\n",
    "    if len(A) == 1:\n",
    "        con_indices.append([-1, -2, -3])\n",
    "        con_tensors.append(A[0])\n",
    "    else:\n",
    "        for k, Ak in enumerate(A):\n",
    "            if k == 0:                                  # first site\n",
    "                con_tensors.append(Ak)\n",
    "                con_indices.append([-1, -2, 1])\n",
    "            elif k < len(A) - 1:                        # middle sites\n",
    "                con_tensors.append(Ak)\n",
    "                con_indices.append([k, -(k+2), k+1])\n",
    "            else:                                       # last of the block\n",
    "                con_tensors.append(Ak)\n",
    "                con_indices.append([k, -(k+2), -(k+3)])\n",
    "    #print(con_indices)\n",
    "\n",
    "    # result has open legs: [-1 (left=1), -2..-(i) (physicals), -(i+1) (right bond Di-1)]\n",
    "    T = ncon(con_tensors, con_indices)\n",
    "    # T.shape == (1, d, d, ..., d, D_{i-1})   # (i-1) copies of d\n",
    "    return T\n",
    "\n",
    "UL = contract_left(tensor=psi,i=3,N=len(B_list))\n",
    "UR = contract_right(tensor=psi,i=3,N=len(B_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28f79546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorial_derivative(psi, b, site):\n",
    "\n",
    "    N_psi = psi.L\n",
    "    N_b  = b.L\n",
    "    if N_psi != N_b:\n",
    "        raise ValueError(f\"psi e b hanno lunghezze diverse: {N_psi} vs {N_b}\")\n",
    "    N = N_psi\n",
    "\n",
    "    if not (1 <= site <= N):\n",
    "        raise ValueError(f\"site={site} fuori range [1, {N}]\")\n",
    "    \n",
    "    UL = contract_left(tensor=psi,i=site,N=N)\n",
    "    UR = contract_right(tensor=psi,i=site,N=N)\n",
    "    BL = contract_left(tensor=b,i=site,N=N)\n",
    "    BR = contract_right(tensor=b,i=site,N=N)\n",
    "\n",
    "    if UL is not None and len(UL.shape) != len(BL.shape):\n",
    "        raise ValueError(f\"Dimensione di UL diversa da BL\")\n",
    "    if UR is not None and len(UR.shape) != len(BR.shape):\n",
    "        raise ValueError(f\"Dimensione di UR diversa da BR\")\n",
    "\n",
    "    if UL is not None:\n",
    "        left_tensors = [UL,BL]\n",
    "        left_links = [\n",
    "            [-1] + [k for k in range(1,site)] + [-2], \n",
    "        [-3] + [k for k in range(1,site)] + [-4] \n",
    "        ]\n",
    "        #print('left contraction links',left_links)\n",
    "        left_contraction = ncon(left_tensors,left_links) \n",
    "    ## Il risultato è un tensore di dimensione (1,D_i;1,2)\n",
    "\n",
    "    if UR is not None:\n",
    "        right_tensors = [UR,BR]\n",
    "        right_links = [\n",
    "            [-1] + [k for k in range(1,N-site+1)] + [-2], \n",
    "        [-3] + [k for k in range(1,N-site+1)] + [-4] \n",
    "        ]\n",
    "        #print('right contraction links',right_links)\n",
    "        right_contraction = ncon(right_tensors,right_links) \n",
    "    ## Il risultato è un tensore di dimensione (D_i+1,1;2,1)\n",
    "\n",
    "    if site > 1 and site < N:\n",
    "        final_tensors = [left_contraction, b.get_B(site-1),right_contraction]\n",
    "        final_links = [\n",
    "            [-1] + [-2] + [-3] + [1],\n",
    "            [1] + [-4] + [2],\n",
    "            [-5] + [-6] + [2] + [-7]\n",
    "        ]\n",
    "        final_contraction = ncon(final_tensors,final_links)\n",
    "        #print(final_links)\n",
    "        #print(final_contraction.shape)\n",
    "\n",
    "    elif site == 1:\n",
    "        final_tensors = [b.get_B(site-1),right_contraction]\n",
    "        final_links = [\n",
    "            [-1] + [-2] + [1],\n",
    "            [-3] + [-4] + [1] + [-5]\n",
    "        ]\n",
    "        final_contraction = ncon(final_tensors,final_links)\n",
    "        #print(final_links)\n",
    "        #print(final_contraction.shape)\n",
    "\n",
    "    elif site == N:\n",
    "        final_tensors = [left_contraction, b.get_B(site-1)]\n",
    "        final_links = [\n",
    "            [-1] + [-2] + [-3] + [1],\n",
    "            [1] + [-4] + [-5],\n",
    "        ]\n",
    "        final_contraction = ncon(final_tensors,final_links)\n",
    "        #print(final_links)\n",
    "        #print(final_contraction.shape)\n",
    "\n",
    "    return np.squeeze(final_contraction)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f1905a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "derivata = tensorial_derivative(psi=psi,b=b, site=9)\n",
    "print(derivata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67140cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Greedy(A: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Greedy compression of the rows of A.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : np.ndarray\n",
    "        Input matrix (2D).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Matrix L encoding the greedy merges/deletions of rows of A.\n",
    "    \"\"\"\n",
    "    if A.ndim != 2:\n",
    "        raise ValueError(\"A deve essere una matrice 2D\")\n",
    "\n",
    "    M = A.copy()\n",
    "    L = np.identity(M.shape[0])\n",
    "\n",
    "    while L.shape[1] > A.shape[1]:\n",
    "        n_rows = M.shape[0]\n",
    "\n",
    "        # Row-wise positive sums\n",
    "        row_sums = np.zeros(n_rows)\n",
    "        for i in range(n_rows):\n",
    "            row = M[i]\n",
    "            row_sums[i] = row[row > 0].sum()\n",
    "\n",
    "        # Gain from merging each pair of rows\n",
    "        merge_gain = np.full((n_rows, n_rows), -np.inf, dtype=float)\n",
    "        for i in range(n_rows):\n",
    "            for j in range(n_rows):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                merged_row = M[i] + M[j]\n",
    "                pos_sum = merged_row[merged_row > 0].sum()\n",
    "                merge_gain[i, j] = pos_sum - row_sums[i] - row_sums[j]\n",
    "\n",
    "        # Greedy choice: best row to drop vs best pair to merge\n",
    "        ropt = np.argmin(row_sums)\n",
    "        iopt, jopt = np.unravel_index(np.argmax(merge_gain), merge_gain.shape)\n",
    "\n",
    "        if merge_gain[iopt, jopt] > -row_sums[ropt]:\n",
    "            # Merge rows iopt and jopt\n",
    "            M[iopt] = M[iopt] + M[jopt]\n",
    "            M = np.delete(M, jopt, axis=0)\n",
    "\n",
    "            L[:, iopt] = L[:, iopt] + L[:, jopt]\n",
    "            L = np.delete(L, jopt, axis=1)\n",
    "        else:\n",
    "            # Drop row ropt\n",
    "            M = np.delete(M, ropt, axis=0)\n",
    "            L = np.delete(L, ropt, axis=1)\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db2a5a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SweepingAlgorithm(b, d, D, err):\n",
    "    N = b.L\n",
    "    psi = build_mps_AR_bond(d=d, N=N, D=D)\n",
    "\n",
    "    # overlap iniziale\n",
    "    k_ref = b.overlap(psi)\n",
    "\n",
    "    # primo update sul sito 1 (come prima)\n",
    "    site = 1\n",
    "    A_tilde = tensorial_derivative(psi=psi, b=b, site=site)\n",
    "    A_prime = A_tilde.to_ndarray()\n",
    "    L_out = Greedy(A_prime)\n",
    "    d_phys, Dr = L_out.shape\n",
    "    L = L_out.reshape(1, d_phys, Dr)\n",
    "    L_tenpy = npc.Array.from_ndarray_trivial(L, labels=['vL', 'p', 'vR'])\n",
    "    psi.set_B(site - 1, L_tenpy)\n",
    "\n",
    "    nstep = 1\n",
    "    updates_since_check = 1   # abbiamo già fatto un update\n",
    "    K = 4        # o N, 2*N, ecc.\n",
    "    max_steps = 100000\n",
    "\n",
    "    while nstep < max_steps:\n",
    "\n",
    "        # sweep left -> right\n",
    "        for i in range(N - 1):\n",
    "            site = i + 1\n",
    "            if site == 1 and nstep == 1:\n",
    "                continue\n",
    "\n",
    "            A_prime = tensorial_derivative(psi=psi, b=b, site=site).to_ndarray()\n",
    "\n",
    "            if 1 < site < N:\n",
    "                Dl, d_phys, Dr = A_prime.shape\n",
    "                L = Greedy(A_prime.reshape(Dl * d_phys, Dr)).reshape(Dl, d_phys, Dr)\n",
    "            else:\n",
    "                d_phys, Dr = A_prime.shape\n",
    "                L =  Greedy(A_prime).reshape(1, d_phys, Dr)\n",
    "\n",
    "            psi.set_B(i, npc.Array.from_ndarray_trivial(L, labels=['vL', 'p', 'vR']))\n",
    "\n",
    "            nstep += 1\n",
    "            updates_since_check += 1\n",
    "\n",
    "            if updates_since_check >= K:\n",
    "                k_curr = b.overlap(psi)\n",
    "                print(k_curr)\n",
    "                if np.abs(k_curr - k_ref) <= err * max(np.abs(k_ref), 1e-12):\n",
    "                    return psi, k_curr, nstep\n",
    "                k_ref = k_curr\n",
    "                updates_since_check = 0\n",
    "\n",
    "        # sweep right -> left\n",
    "        for j in range(N - 1, 0, -1):\n",
    "            site = j + 1\n",
    "            A_prime = tensorial_derivative(psi=psi, b=b, site=site).to_ndarray()\n",
    "\n",
    "            if 1 < site < N:\n",
    "                Dl, d_phys, Dr = A_prime.shape\n",
    "                R = Greedy(A_prime.reshape(Dl, Dr * d_phys).T).T.reshape(Dl, d_phys, Dr)\n",
    "            else:\n",
    "                Dl, d_phys = A_prime.shape\n",
    "                R = Greedy(A_prime.T).T.reshape(Dl, d_phys, 1)\n",
    "\n",
    "            psi.set_B(j, npc.Array.from_ndarray_trivial(R, labels=['vL', 'p', 'vR']))\n",
    "\n",
    "            nstep += 1\n",
    "            updates_since_check += 1\n",
    "\n",
    "            if updates_since_check >= K:\n",
    "                k_curr = b.overlap(psi)\n",
    "                print(k_curr)\n",
    "                if np.abs(k_curr - k_ref) <= err * max(np.abs(k_ref), 1e-12):\n",
    "                    return psi, k_curr, nstep\n",
    "                k_ref = k_curr\n",
    "                updates_since_check = 0\n",
    "\n",
    "    raise RuntimeError(\"SweepingAlgorithm did not converge within max_steps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53a86aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-169.5226173786392\n",
      "-4.3130289518837435\n",
      "-0.000864561722363013\n",
      "0.13989025923287063\n",
      "-0.6103723804708819\n",
      "-1.5322657992286115\n",
      "6.319016005740293\n",
      "-5.782951923714216\n",
      "-2.731761894163892\n",
      "-0.1478718794077264\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m B_list = build_B_list(S0, K, N, d_op, m_op, u_op, pd, pu)\n\u001b[32m      3\u001b[39m b = build_mps(B_list, d=\u001b[32m3\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m psi , K, nstep = \u001b[43mSweepingAlgorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-18\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(nstep)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mSweepingAlgorithm\u001b[39m\u001b[34m(b, d, D, err)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N - \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, -\u001b[32m1\u001b[39m):\n\u001b[32m     55\u001b[39m     site = j + \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     A_prime = \u001b[43mtensorial_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msite\u001b[49m\u001b[43m=\u001b[49m\u001b[43msite\u001b[49m\u001b[43m)\u001b[49m.to_ndarray()\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m1\u001b[39m < site < N:\n\u001b[32m     59\u001b[39m         Dl, d_phys, Dr = A_prime.shape\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtensorial_derivative\u001b[39m\u001b[34m(psi, b, site)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m1\u001b[39m <= site <= N):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msite=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msite\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fuori range [1, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m UL = \u001b[43mcontract_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m=\u001b[49m\u001b[43msite\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m UR = contract_right(tensor=psi,i=site,N=N)\n\u001b[32m     14\u001b[39m BL = contract_left(tensor=b,i=site,N=N)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mcontract_left\u001b[39m\u001b[34m(tensor, i, N)\u001b[39m\n\u001b[32m     38\u001b[39m             con_indices.append([k, -(k+\u001b[32m2\u001b[39m), -(k+\u001b[32m3\u001b[39m)])\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m#print(con_indices)\u001b[39;00m\n\u001b[32m     40\u001b[39m \n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# result has open legs: [-1 (left=1), -2..-(i) (physicals), -(i+1) (right bond Di-1)]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m T = \u001b[43mncon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# T.shape == (1, d, d, ..., d, D_{i-1})   # (i-1) copies of d\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m T\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/moodys/Semester Project Moodys/repo_moody/.venv/lib/python3.12/site-packages/tenpy/algorithms/network_contractor.py:50\u001b[39m, in \u001b[36mncon\u001b[39m\u001b[34m(tensor_list, leg_links, sequence)\u001b[39m\n\u001b[32m     48\u001b[39m tensor_list, leg_links, sequence = _ncon_input_checks(tensor_list, leg_links, sequence)\n\u001b[32m     49\u001b[39m tensor_list, leg_links, sequence = _ncon_do_traces(tensor_list, leg_links, sequence)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m tensor_list, leg_links, sequence = \u001b[43m_ncon_do_binary_contractions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleg_links\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m tensor_list, leg_links = _ncon_do_outer_products(tensor_list, leg_links)\n\u001b[32m     52\u001b[39m result, = tensor_list\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/moodys/Semester Project Moodys/repo_moody/.venv/lib/python3.12/site-packages/tenpy/algorithms/network_contractor.py:249\u001b[39m, in \u001b[36m_ncon_do_binary_contractions\u001b[39m\u001b[34m(tensor_list, leg_links, sequence)\u001b[39m\n\u001b[32m    246\u001b[39m common_values, a_axes, b_axes = np.intersect1d(links_a, links_b, assume_unique=\u001b[38;5;28;01mTrue\u001b[39;00m, return_indices=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     res = \u001b[43mnpc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_axes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    251\u001b[39m     msg = (\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAn error occurred while performing the pairwise contraction indicated by \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    252\u001b[39m            \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mvalues \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(common_values)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in leg_links. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    253\u001b[39m            \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mOriginal stacktrace below.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/moodys/Semester Project Moodys/repo_moody/.venv/lib/python3.12/site-packages/tenpy/linalg/np_conserved.py:3567\u001b[39m, in \u001b[36mtensordot\u001b[39m\u001b[34m(a, b, axes)\u001b[39m\n\u001b[32m   3539\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Similar as ``np.tensordot`` but for :class:`Array`.\u001b[39;00m\n\u001b[32m   3540\u001b[39m \n\u001b[32m   3541\u001b[39m \u001b[33;03mBuilds the tensor product of `a` and `b` and sums over the specified axes.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3564\u001b[39m \u001b[33;03m    Returns a scalar in case of a full contraction.\u001b[39;00m\n\u001b[32m   3565\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3566\u001b[39m \u001b[38;5;66;03m# for details on the implementation, see _tensordot_worker.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3567\u001b[39m a, b, axes = \u001b[43m_tensordot_transpose_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3569\u001b[39m \u001b[38;5;66;03m# optimize/check for special cases\u001b[39;00m\n\u001b[32m   3570\u001b[39m no_block = (a.stored_blocks == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m b.stored_blocks == \u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# result is zero\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/moodys/Semester Project Moodys/repo_moody/.venv/lib/python3.12/site-packages/tenpy/linalg/_npc_helper.pyx:1289\u001b[39m, in \u001b[36mtenpy.linalg._npc_helper._tensordot_transpose_axes\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/moodys/Semester Project Moodys/repo_moody/.venv/lib/python3.12/site-packages/tenpy/tools/optimization.py:231\u001b[39m, in \u001b[36moptimize\u001b[39m\u001b[34m(level_compare)\u001b[39m\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mglobal\u001b[39;00m _level  \u001b[38;5;66;03m# noqa: F824\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _level\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(level_compare=OptimizationFlag.default):\n\u001b[32m    232\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Called by algorithms to check whether it should (try to) do some optimizations.\u001b[39;00m\n\u001b[32m    233\u001b[39m \n\u001b[32m    234\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m \u001b[33;03m        \"optimization level\" is equal or higher than the level to compare to.\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mglobal\u001b[39;00m _level  \u001b[38;5;66;03m# noqa: F824\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "N = 15\n",
    "B_list = build_B_list(S0, K, N, d_op, m_op, u_op, pd, pu)\n",
    "b = build_mps(B_list, d=3)\n",
    "psi , K, nstep = SweepingAlgorithm(b=b, d=3, D=10, err=1e-18)\n",
    "print(nstep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
